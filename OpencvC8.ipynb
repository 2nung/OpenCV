{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87549e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_digits():\n",
    "    img_digits = []\n",
    "\n",
    "    for i in range(10):\n",
    "        filename = 'data/digits/digit{}.bmp'.format(i)\n",
    "        img_digits.append(cv2.imread(filename, cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "        if img_digits[i] is None:\n",
    "            return None\n",
    "\n",
    "    return img_digits\n",
    "\n",
    "\n",
    "def find_digit(img, img_digits):\n",
    "    max_idx = -1\n",
    "    max_ccoeff = -1\n",
    "\n",
    "    # 최대 NCC 찾기\n",
    "    for i in range(10):\n",
    "        img = cv2.resize(img, (100, 150))\n",
    "        res = cv2.matchTemplate(img, img_digits[i], cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "        if res[0, 0] > max_ccoeff:\n",
    "            max_idx = i\n",
    "            max_ccoeff = res[0, 0]\n",
    "\n",
    "    return max_idx\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 입력 영상 불러오기\n",
    "    src = cv2.imread('data/digits_print.bmp')\n",
    "\n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    # 100x150 숫자 영상 불러오기\n",
    "    img_digits = load_digits()  # list of ndarray\n",
    "\n",
    "    if img_digits is None:\n",
    "        print('Digit image load failed!')\n",
    "        return\n",
    "\n",
    "    # 입력 영상 이진화 & 레이블링\n",
    "    src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    _, src_bin = cv2.threshold(src_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "    cnt, _, stats, _ = cv2.connectedComponentsWithStats(src_bin)\n",
    "\n",
    "    # 숫자 인식 결과 영상 생성\n",
    "    dst = src.copy()\n",
    "    for i in range(1, cnt):\n",
    "        (x, y, w, h, s) = stats[i]\n",
    "\n",
    "        if s < 1000:\n",
    "            continue\n",
    "\n",
    "        # 가장 유사한 숫자 이미지를 선택\n",
    "        digit = find_digit(src_gray[y:y+h, x:x+w], img_digits)\n",
    "        cv2.rectangle(dst, (x, y, w, h), (0, 255, 255))\n",
    "        cv2.putText(dst, str(digit), (x, y - 4), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('data/lenna.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('data/haarcascade_frontalface_alt2.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('data/haarcascade_eye.xml')\n",
    "\n",
    "if face_classifier.empty() or eye_classifier.empty():\n",
    "    print('XML load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "faces = face_classifier.detectMultiScale(src)\n",
    "\n",
    "for (x1, y1, w1, h1) in faces:\n",
    "    cv2.rectangle(src, (x1, y1), (x1 + w1, y1 + h1), (255, 0, 255), 2)\n",
    "\n",
    "    faceROI = src[y1:y1 + h1 // 2, x1:x1 + w1]\n",
    "    eyes = eye_classifier.detectMultiScale(faceROI)\n",
    "\n",
    "    for (x2, y2, w2, h2) in eyes:\n",
    "        center = (x2 + w2 // 2, y2 + h2 // 2)\n",
    "        cv2.circle(faceROI, center, w2 // 2, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3924656",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('data/lenna.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "classifier = cv2.CascadeClassifier('data/haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "if classifier.empty():\n",
    "    print('XML load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "faces = classifier.detectMultiScale(src)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(src, (x, y, w, h), (255, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54728f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 영상 불러오기\n",
    "src = cv2.imread('data/nemo.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 사각형 지정을 통한 초기 분할\n",
    "rc = cv2.selectROI(src)\n",
    "mask = np.zeros(src.shape[:2], np.uint8)\n",
    "\n",
    "cv2.grabCut(src, mask, rc, None, None, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "# 0: cv2.GC_BGD, 2: cv2.GC_PR_BGD\n",
    "mask2 = np.where((mask == 0) | (mask == 2), 0, 1).astype('uint8')\n",
    "dst = src * mask2[:, :, np.newaxis]\n",
    "\n",
    "# 초기 분할 결과 출력\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 영상 불러오기\n",
    "src = cv2.imread('messi5.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 사각형 지정을 통한 초기 분할\n",
    "mask = np.zeros(src.shape[:2], np.uint8)  # 마스크\n",
    "bgdModel = np.zeros((1, 65), np.float64)  # 배경 모델\n",
    "fgdModel = np.zeros((1, 65), np.float64)  # 전경 모델\n",
    "\n",
    "rc = cv2.selectROI(src)\n",
    "\n",
    "cv2.grabCut(src, mask, rc, bgdModel, fgdModel, 1, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "# 0: cv2.GC_BGD, 2: cv2.GC_PR_BGD\n",
    "mask2 = np.where((mask == 0) | (mask == 2), 0, 1).astype('uint8')\n",
    "dst = src * mask2[:, :, np.newaxis]\n",
    "\n",
    "# 초기 분할 결과 출력\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "# 마우스 이벤트 처리 함수 등록\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(dst, (x, y), 3, (255, 0, 0), -1)\n",
    "        cv2.circle(mask, (x, y), 3, cv2.GC_FGD, -1)\n",
    "        cv2.imshow('dst', dst)\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        cv2.circle(dst, (x, y), 3, (0, 0, 255), -1)\n",
    "        cv2.circle(mask, (x, y), 3, cv2.GC_BGD, -1)\n",
    "        cv2.imshow('dst', dst)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.circle(dst, (x, y), 3, (255, 0, 0), -1)\n",
    "            cv2.circle(mask, (x, y), 3, cv2.GC_FGD, -1)\n",
    "            cv2.imshow('dst', dst)\n",
    "        elif flags & cv2.EVENT_FLAG_RBUTTON:\n",
    "            cv2.circle(dst, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.circle(mask, (x, y), 3, cv2.GC_BGD, -1)\n",
    "            cv2.imshow('dst', dst)\n",
    "\n",
    "\n",
    "cv2.setMouseCallback('dst', on_mouse)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey()\n",
    "    if key == 13:  # ENTER\n",
    "        # 사용자가 지정한 전경/배경 정보를 활용하여 영상 분할\n",
    "        cv2.grabCut(src, mask, rc, bgdModel, fgdModel, 1, cv2.GC_INIT_WITH_MASK)\n",
    "        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "        dst = src * mask2[:, :, np.newaxis]\n",
    "        cv2.imshow('dst', dst)\n",
    "    elif key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0fb3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 불러오기\n",
    "obj = cv2.imread('data/spades.png', cv2.IMREAD_GRAYSCALE)\n",
    "src = cv2.imread('data/symbols.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None or obj is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 객체 영상 외곽선 검출\n",
    "_, obj_bin = cv2.threshold(obj, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "obj_contours, _ = cv2.findContours(obj_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "obj_pts = obj_contours[0]\n",
    "\n",
    "# 입력 영상 분석\n",
    "_, src_bin = cv2.threshold(src, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "contours, _ = cv2.findContours(src_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# 결과 영상\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# 입력 영상의 모든 객체 영역에 대해서\n",
    "for pts in contours:\n",
    "    if cv2.contourArea(pts) < 1000:\n",
    "        continue\n",
    "\n",
    "    rc = cv2.boundingRect(pts)\n",
    "    cv2.rectangle(dst, rc, (255, 0, 0), 1)\n",
    "\n",
    "    # 모양 비교\n",
    "    dist = cv2.matchShapes(obj_pts, pts, cv2.CONTOURS_MATCH_I3, 0)\n",
    "\n",
    "    cv2.putText(dst, str(round(dist, 4)), (rc[0], rc[1] - 3),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    if dist < 0.1:\n",
    "        cv2.rectangle(dst, rc, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('obj', obj)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f967b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동영상 불러오기\n",
    "cap = cv2.VideoCapture('data/vtest.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 보행자 검출을 위한 HOG 기술자 설정\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 매 프레임마다 보행자 검출\n",
    "    detected, _ = hog.detectMultiScale(frame)\n",
    "\n",
    "    # 검출 결과 화면 표시\n",
    "    for (x, y, w, h) in detected:\n",
    "        c = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "        cv2.rectangle(frame, (x, y, w, h), c, 3)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(10) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba48917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3채널 img 영상에 4채널 item 영상을 pos 위치에 합성\n",
    "def overlay(img, glasses, pos):\n",
    "    # 실제 합성을 수행할 부분 영상 좌표 계산\n",
    "    sx = pos[0]\n",
    "    ex = pos[0] + glasses.shape[1]\n",
    "    sy = pos[1]\n",
    "    ey = pos[1] + glasses.shape[0]\n",
    "\n",
    "    # 합성할 영역이 입력 영상 크기를 벗어나면 무시\n",
    "    if sx < 0 or sy < 0 or ex > img.shape[1] or ey > img.shape[0]:\n",
    "        return\n",
    "\n",
    "    # 부분 영상 참조. img1: 입력 영상의 부분 영상, img2: 안경 영상의 부분 영상\n",
    "    img1 = img[sy:ey, sx:ex]   # shape=(h, w, 3)\n",
    "    img2 = glasses[:, :, 0:3]  # shape=(h, w, 3)\n",
    "    alpha = 1. - (glasses[:, :, 3] / 255.)  # shape=(h, w)\n",
    "\n",
    "    # BGR 채널별로 두 부분 영상의 가중합\n",
    "    img1[..., 0] = (img1[..., 0] * alpha + img2[..., 0] * (1. - alpha)).astype(np.uint8)\n",
    "    img1[..., 1] = (img1[..., 1] * alpha + img2[..., 1] * (1. - alpha)).astype(np.uint8)\n",
    "    img1[..., 2] = (img1[..., 2] * alpha + img2[..., 2] * (1. - alpha)).astype(np.uint8)\n",
    "\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 30, (w, h))\n",
    "\n",
    "# Haar-like XML 파일 열기\n",
    "face_classifier = cv2.CascadeClassifier('data/haarcascade_frontalface_alt2.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('data/haarcascade_eye.xml')\n",
    "\n",
    "if face_classifier.empty() or eye_classifier.empty():\n",
    "    print('XML load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 안경 PNG 파일 열기 (Image from http://www.pngall.com/)\n",
    "glasses = cv2.imread('data/glasses.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "if glasses is None:\n",
    "    print('PNG image open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "ew, eh = glasses.shape[:2]  # 가로, 세로 크기\n",
    "ex1, ey1 = 240, 300  # 왼쪽 눈 좌표\n",
    "ex2, ey2 = 660, 300  # 오른쪽 눈 좌표\n",
    "\n",
    "# 매 프레임에 대해 얼굴 검출 및 안경 합성\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 얼굴 검출\n",
    "    faces = face_classifier.detectMultiScale(frame, scaleFactor=1.2,\n",
    "                                             minSize=(100, 100), maxSize=(400, 400))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        #cv2.rectangle(frame, (x, y, w, h), (255, 0, 255), 2)\n",
    "\n",
    "        # 눈 검출\n",
    "        faceROI = frame[y:y + h // 2, x:x + w]\n",
    "        eyes = eye_classifier.detectMultiScale(faceROI)\n",
    "\n",
    "        # 눈을 2개 검출한 것이 아니라면 무시\n",
    "        if len(eyes) != 2:\n",
    "            continue\n",
    "\n",
    "        # 두 개의 눈 중앙 위치를 (x1, y1), (x2, y2) 좌표로 저장\n",
    "        x1 = x + eyes[0][0] + (eyes[0][2] // 2)\n",
    "        y1 = y + eyes[0][1] + (eyes[0][3] // 2)\n",
    "        x2 = x + eyes[1][0] + (eyes[1][2] // 2)\n",
    "        y2 = y + eyes[1][1] + (eyes[1][3] // 2)\n",
    "\n",
    "        if x1 > x2:\n",
    "            x1, y1, x2, y2 = x2, y2, x1, y1\n",
    "\n",
    "        #cv2.circle(faceROI, (x1, y1), 5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        #cv2.circle(faceROI, (x2, y2), 5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # 두 눈 사이의 거리를 이용하여 스케일링 팩터를 계산 (두 눈이 수평하다고 가정)\n",
    "        fx = (x2 - x1) / (ex2 - ex1)\n",
    "        glasses2 = cv2.resize(glasses, (0, 0), fx=fx, fy=fx, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # 크기 조절된 안경 영상을 합성할 위치 계산 (좌상단 좌표)\n",
    "        pos = (x1 - int(ex1 * fx), y1 - int(ey1 * fx))\n",
    "\n",
    "        # 영상 합성\n",
    "        overlay(frame, glasses2, pos)\n",
    "\n",
    "    # 프레임 저장 및 화면 출력\n",
    "    out.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94864744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxv: 0.9796600341796875\n",
      "maxloc: (568, 320)\n"
     ]
    }
   ],
   "source": [
    "# 입력 영상 & 템플릿 영상 불러오기\n",
    "src = cv2.imread('data/circuit.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "templ = cv2.imread('data/crystal.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None or templ is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 입력 영상 밝기 50증가, 가우시안 잡음(sigma=10) 추가\n",
    "noise = np.zeros(src.shape, np.int32)\n",
    "cv2.randn(noise, 50, 10)\n",
    "src = cv2.add(src, noise, dtype=cv2.CV_8UC3)\n",
    "\n",
    "# 템플릿 매칭 & 결과 분석\n",
    "res = cv2.matchTemplate(src, templ, cv2.TM_CCOEFF_NORMED)\n",
    "res_norm = cv2.normalize(res, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "\n",
    "_, maxv, _, maxloc = cv2.minMaxLoc(res)\n",
    "print('maxv:', maxv)\n",
    "print('maxloc:', maxloc)\n",
    "\n",
    "# 매칭 결과를 빨간색 사각형으로 표시\n",
    "th, tw = templ.shape[:2]\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "cv2.rectangle(dst, maxloc, (maxloc[0] + tw, maxloc[1] + th), (0, 0, 255), 2)\n",
    "\n",
    "# 결과 영상 화면 출력\n",
    "cv2.imshow('res_norm', res_norm)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
