{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e201601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd125d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기준 영상 불러오기\n",
    "src = cv2.imread('data/korea.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 카메라 장치 열기\n",
    "cap1 = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap1.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 필요할 경우 카메라 해상도 변경\n",
    "#cap1.set(cv2.CAP_PROP_FRAME_WIDTH, 800)\n",
    "#cap1.set(cv2.CAP_PROP_FRAME_HEIGHT, 600)\n",
    "\n",
    "# 카메라 프레임 화면에 출력할 동영상 파일 열기\n",
    "cap2 = cv2.VideoCapture('data/korea.mp4')\n",
    "\n",
    "if not cap2.isOpened():\n",
    "    print('Video load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# AKAZE 특징점 알고리즘 객체 생성\n",
    "detector = cv2.AKAZE_create()\n",
    "\n",
    "# 기준 영상에서 특징점 검출 및 기술자 생성\n",
    "kp1, desc1 = detector.detectAndCompute(src, None)\n",
    "\n",
    "# 해밍 거리를 사용하는 매칭 객체 생성\n",
    "matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "\n",
    "while True:\n",
    "    ret1, frame1 = cap1.read()\n",
    "\n",
    "    if not ret1:\n",
    "        break\n",
    "\n",
    "    # 매 프레임마다 특징점 검출 및 기술자 생성\n",
    "    gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    kp2, desc2 = detector.detectAndCompute(gray, None)\n",
    "\n",
    "    # 특징점이 100개 이상 검출될 경우 매칭 수행\n",
    "    if len(kp2) > 100:\n",
    "        matches = matcher.match(desc1, desc2)\n",
    "\n",
    "        # 좋은 매칭 선별\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "        good_matches = matches[:80]\n",
    "\n",
    "        pts1 = np.array([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2).astype(np.float32)\n",
    "        pts2 = np.array([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "        # 호모그래피 계산\n",
    "        H, inliers = cv2.findHomography(pts1, pts2, cv2.RANSAC)\n",
    "\n",
    "        inlier_cnt = cv2.countNonZero(inliers)\n",
    "\n",
    "        # RANSAC 방법에서 정상적으로 매칭된 것의 개수가 20개 이상이면\n",
    "        if inlier_cnt > 20:\n",
    "            ret2, frame2 = cap2.read()\n",
    "\n",
    "            if not ret2:\n",
    "                break\n",
    "\n",
    "            h, w = frame1.shape[:2]\n",
    "\n",
    "            # 비디오 프레임을 투시 변환\n",
    "            video_warp = cv2.warpPerspective(frame2, H, (w, h))\n",
    "\n",
    "            white = np.full(frame2.shape[:2], 255, np.uint8)\n",
    "            white = cv2.warpPerspective(white, H, (w, h))\n",
    "\n",
    "            # 비디오 프레임을 카메라 프레임에 합성\n",
    "            cv2.copyTo(video_warp, white, frame1)\n",
    "\n",
    "    cv2.imshow('frame', frame1)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e05129",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('data/building.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "tm = cv2.TickMeter()\n",
    "\n",
    "# GFTT\n",
    "tm.start()\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(src, 400, 0.01, 10)\n",
    "\n",
    "tm.stop()\n",
    "print('GFTT: {}ms.'.format(tm.getTimeMilli()))\n",
    "\n",
    "dst1 = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "if corners is not None:\n",
    "    for i in range(corners.shape[0]):\n",
    "        pt = (int(corners[i, 0, 0]), int(corners[i, 0, 1]))\n",
    "        cv2.circle(dst1, pt, 5, (0, 0, 255), 2)\n",
    "\n",
    "# FAST\n",
    "tm.reset()\n",
    "tm.start()\n",
    "\n",
    "fast = cv2.FastFeatureDetector_create(60)\n",
    "keypoints = fast.detect(src)\n",
    "\n",
    "tm.stop()\n",
    "print('FAST: {}ms.'.format(tm.getTimeMilli()))\n",
    "\n",
    "dst2 = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for kp in keypoints:\n",
    "    pt = (int(kp.pt[0]), int(kp.pt[1]))\n",
    "    cv2.circle(dst2, pt, 5, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst1', dst1)\n",
    "cv2.imshow('dst2', dst2)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b48647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc1.shape: (3159, 64)\n",
      "desc1.dtype: float32\n",
      "desc2.shape: (3625, 64)\n",
      "desc2.dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# 영상 불러오기\n",
    "src1 = cv2.imread('data/graf1.png', cv2.IMREAD_GRAYSCALE)\n",
    "src2 = cv2.imread('data/graf3.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src1 is None or src2 is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 특징점 알고리즘 객체 생성 (KAZE, AKAZE, ORB 등)\n",
    "feature = cv2.KAZE_create()\n",
    "#feature = cv2.AKAZE_create()\n",
    "#feature = cv2.ORB_create()\n",
    "\n",
    "# 특징점 검출 및 기술자 계산\n",
    "kp1 = feature.detect(src1)\n",
    "_, desc1 = feature.compute(src1, kp1)\n",
    "\n",
    "kp2, desc2 = feature.detectAndCompute(src2, None)\n",
    "\n",
    "print('desc1.shape:', desc1.shape)\n",
    "print('desc1.dtype:', desc1.dtype)\n",
    "print('desc2.shape:', desc2.shape)\n",
    "print('desc2.dtype:', desc2.dtype)\n",
    "\n",
    "# 검출된 특징점 출력 영상 생성\n",
    "dst1 = cv2.drawKeypoints(src1, kp1, None,\n",
    "                         flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "dst2 = cv2.drawKeypoints(src2, kp2, None,\n",
    "                         flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('dst1', dst1)\n",
    "cv2.imshow('dst2', dst2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3645332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 불러오기\n",
    "src1 = cv2.imread('graf1.png', cv2.IMREAD_GRAYSCALE)\n",
    "src2 = cv2.imread('graf3.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src1 is None or src2 is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 특징점 알고리즘 객체 생성 (KAZE, AKAZE, ORB 등)\n",
    "feature = cv2.KAZE_create()\n",
    "#feature = cv2.AKAZE_create()\n",
    "#feature = cv2.ORB_create()\n",
    "\n",
    "# 특징점 검출 및 기술자 계산\n",
    "kp1, desc1 = feature.detectAndCompute(src1, None)\n",
    "kp2, desc2 = feature.detectAndCompute(src2, None)\n",
    "\n",
    "# 특징점 매칭\n",
    "matcher = cv2.BFMatcher_create()\n",
    "#matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "matches = matcher.match(desc1, desc2)\n",
    "\n",
    "# 좋은 매칭 결과 선별\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "good_matches = matches[:80]\n",
    "\n",
    "print('# of kp1:', len(kp1))\n",
    "print('# of kp2:', len(kp2))\n",
    "print('# of matches:', len(matches))\n",
    "print('# of good_matches:', len(good_matches))\n",
    "\n",
    "# 특징점 매칭 결과 영상 생성\n",
    "dst = cv2.drawMatches(src1, kp1, src2, kp2, good_matches, None)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a6f16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of kp1: 3159\n",
      "# of kp2: 3625\n",
      "# of matches: 3159\n",
      "# of good_matches: 384\n"
     ]
    }
   ],
   "source": [
    "# 영상 불러오기\n",
    "src1 = cv2.imread('data/graf1.png', cv2.IMREAD_GRAYSCALE)\n",
    "src2 = cv2.imread('data/graf3.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src1 is None or src2 is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 특징점 알고리즘 객체 생성 (KAZE, AKAZE, ORB 등)\n",
    "feature = cv2.KAZE_create()\n",
    "#feature = cv2.AKAZE_create()\n",
    "#feature = cv2.ORB_create()\n",
    "\n",
    "# 특징점 검출 및 기술자 계산\n",
    "kp1, desc1 = feature.detectAndCompute(src1, None)\n",
    "kp2, desc2 = feature.detectAndCompute(src2, None)\n",
    "\n",
    "# 특징점 매칭\n",
    "matcher = cv2.BFMatcher_create()\n",
    "#matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "matches = matcher.knnMatch(desc1, desc2, 2)\n",
    "\n",
    "# 좋은 매칭 결과 선별\n",
    "good_matches = []\n",
    "for m in matches:\n",
    "    if m[0].distance / m[1].distance < 0.7:\n",
    "        good_matches.append(m[0])\n",
    "\n",
    "print('# of kp1:', len(kp1))\n",
    "print('# of kp2:', len(kp2))\n",
    "print('# of matches:', len(matches))\n",
    "print('# of good_matches:', len(good_matches))\n",
    "\n",
    "# 특징점 매칭 결과 영상 생성\n",
    "dst = cv2.drawMatches(src1, kp1, src2, kp2, good_matches, None)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54eee17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of kp1: 3159\n",
      "# of kp2: 3625\n",
      "# of matches: 3159\n",
      "# of good_matches: 80\n"
     ]
    }
   ],
   "source": [
    "# 영상 불러오기\n",
    "src1 = cv2.imread('data/graf1.png', cv2.IMREAD_GRAYSCALE)\n",
    "src2 = cv2.imread('data/graf3.png', cv2.IMREAD_GRAYSCALE)\n",
    "#src1 = cv2.imread('box.png', cv2.IMREAD_GRAYSCALE)\n",
    "#src2 = cv2.imread('box_in_scene.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src1 is None or src2 is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 특징점 알고리즘 객체 생성 (KAZE, AKAZE, ORB 등)\n",
    "feature = cv2.KAZE_create()\n",
    "#feature = cv2.AKAZE_create()\n",
    "#feature = cv2.ORB_create()\n",
    "\n",
    "# 특징점 검출 및 기술자 계산\n",
    "kp1, desc1 = feature.detectAndCompute(src1, None)\n",
    "kp2, desc2 = feature.detectAndCompute(src2, None)\n",
    "\n",
    "# 특징점 매칭\n",
    "matcher = cv2.BFMatcher_create()\n",
    "#matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "matches = matcher.match(desc1, desc2)\n",
    "\n",
    "# 좋은 매칭 결과 선별\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "good_matches = matches[:80]\n",
    "\n",
    "print('# of kp1:', len(kp1))\n",
    "print('# of kp2:', len(kp2))\n",
    "print('# of matches:', len(matches))\n",
    "print('# of good_matches:', len(good_matches))\n",
    "\n",
    "# 호모그래피 계산\n",
    "pts1 = np.array([kp1[m.queryIdx].pt for m in good_matches]\n",
    "                ).reshape(-1, 1, 2).astype(np.float32)\n",
    "pts2 = np.array([kp2[m.trainIdx].pt for m in good_matches]\n",
    "                ).reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "H, _ = cv2.findHomography(pts1, pts2, cv2.RANSAC)\n",
    "\n",
    "# 호모그래피를 이용하여 기준 영상 영역 표시\n",
    "dst = cv2.drawMatches(src1, kp1, src2, kp2, good_matches, None,\n",
    "                      flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "(h, w) = src1.shape[:2]\n",
    "corners1 = np.array([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]\n",
    "                    ).reshape(-1, 1, 2).astype(np.float32)\n",
    "corners2 = cv2.perspectiveTransform(corners1, H)\n",
    "corners2 = corners2 + np.float32([w, 0])\n",
    "\n",
    "cv2.polylines(dst, [np.int32(corners2)], True, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df08521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 불러오기\n",
    "src1 = cv2.imread('data/graf1.png', cv2.IMREAD_GRAYSCALE)\n",
    "src2 = cv2.imread('data/graf3.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src1 is None or src2 is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 특징점 알고리즘 객체 생성 (KAZE, AKAZE, ORB 등)\n",
    "feature = cv2.KAZE_create()\n",
    "#feature = cv2.AKAZE_create()\n",
    "#feature = cv2.ORB_create()\n",
    "\n",
    "# 특징점 검출\n",
    "kp1 = feature.detect(src1)\n",
    "kp2 = feature.detect(src2)\n",
    "\n",
    "print('# of kp1:', len(kp1))\n",
    "print('# of kp2:', len(kp2))\n",
    "\n",
    "# 검출된 특징점 출력 영상 생성\n",
    "dst1 = cv2.drawKeypoints(src1, kp1, None,\n",
    "                         flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "dst2 = cv2.drawKeypoints(src2, kp2, None,\n",
    "                         flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('dst1', dst1)\n",
    "cv2.imshow('dst2', dst2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa786365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of kp1: 3159\n",
      "# of kp2: 3625\n",
      "# of matches: 3159\n"
     ]
    }
   ],
   "source": [
    "# 영상 불러오기\n",
    "src1 = cv2.imread('data/graf1.png', cv2.IMREAD_GRAYSCALE)\n",
    "src2 = cv2.imread('data/graf3.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src1 is None or src2 is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 특징점 알고리즘 객체 생성 (KAZE, AKAZE, ORB 등)\n",
    "feature = cv2.KAZE_create()\n",
    "#feature = cv2.AKAZE_create()\n",
    "#feature = cv2.ORB_create()\n",
    "\n",
    "# 특징점 검출 및 기술자 계산\n",
    "kp1, desc1 = feature.detectAndCompute(src1, None)\n",
    "kp2, desc2 = feature.detectAndCompute(src2, None)\n",
    "\n",
    "# 특징점 매칭\n",
    "matcher = cv2.BFMatcher_create()\n",
    "#matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "matches = matcher.match(desc1, desc2)\n",
    "\n",
    "print('# of kp1:', len(kp1))\n",
    "print('# of kp2:', len(kp2))\n",
    "print('# of matches:', len(matches))\n",
    "\n",
    "# 특징점 매칭 결과 영상 생성\n",
    "dst = cv2.drawMatches(src1, kp1, src2, kp2, matches, None)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f19e4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = ['data/img1.jpg', 'data/img2.jpg', 'data/img3.jpg']\n",
    "\n",
    "imgs = []\n",
    "for name in img_names:\n",
    "    img = cv2.imread(name)\n",
    "\n",
    "    if img is None:\n",
    "        print('Image load failed!')\n",
    "        sys.exit()\n",
    "\n",
    "    imgs.append(img)\n",
    "\n",
    "stitcher = cv2.Stitcher_create()\n",
    "status, dst = stitcher.stitch(imgs)\n",
    "\n",
    "if status != cv2.Stitcher_OK:\n",
    "    print('Stitch failed!')\n",
    "    sys.exit()\n",
    "\n",
    "cv2.imwrite('output.jpg', dst)\n",
    "\n",
    "cv2.namedWindow('dst', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
